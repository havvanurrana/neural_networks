{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP1UjFH/K6DRUo/jGyuHPVw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/havvanurrana/neural_networks/blob/main/neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Er-VhcWQP_j5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Girdiler (X) metrekare ve oda sayÄ±sÄ±\n",
        "X =np.array([[50,1],[60,1],[80,2],[100,2],[120,3],[150,3],[200,4]], dtype=float)\n",
        "#Hedefler evin fiyatÄ±\n",
        "y =np.array([100,120,160,200,240,300,400], dtype=float)\n"
      ],
      "metadata": {
        "id": "rpC5o5sGRPSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN Mimarisi\n",
        "model = Sequential([\n",
        "    #GiriÅŸ katmanÄ± ve ilk gizli katman\n",
        "    #2 veri alma 10 nÃ¶ronlu bir gizli katman\n",
        "    Dense(units=10, activation='relu', input_shape=[2]),\n",
        "    Dense(units=5, activation='relu'),\n",
        "    Dense(units=1)\n",
        "\n",
        "])\n",
        "model.compile(optimizer='adam', loss ='mean_squared_error')"
      ],
      "metadata": {
        "id": "CjbJaDpeRPfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"EÄŸitim baÅŸlÄ±yor\")\n",
        "history = model.fit(X,y, epochs=500,verbose =0)\n",
        "print(\"EÄŸitim tamam\")\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model HatasÄ± (loss) ')\n",
        "plt.xlabel(\"EPOCH sayÄ±sÄ±\")\n",
        "plt.ylabel('Hata')\n",
        "plt.show"
      ],
      "metadata": {
        "id": "qofX6MjAhwtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test =np.array([[130,3]], dtype=float)\n",
        "tahmin =model.predict(test)\n",
        "print(f\"tahmin sonucu\\n\")\n",
        "print(f\"girdi: 130 m^2 ve 3 oda\")\n",
        "print(f\"modelin biÃ§tiÄŸi fiyat: {tahmin[0][0]:.2f}\")"
      ],
      "metadata": {
        "id": "vwwbHRoejcsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "D6fEQxTSlTbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "train_images, test_images = train_images/255.0 , test_images/255.0\n",
        "class_names =['ucak', 'araba', 'kus', 'kedi', 'geyik', 'kopek', 'kurbaÄŸa', 'at', 'gemi', 'kamyon']\n",
        "plt.figure(figsize=(10,2))\n",
        "for i in range(5):\n",
        "    plt.subplot(1,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i])\n",
        "    plt.xlabel(class_names[train_labels[i][0]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H3YMoMDBrLlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN Mimarisi TasarÄ±mÄ±\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "cnn_model = models.Sequential([\n",
        "    # 1.EvriÅŸim katmanÄ±,(32 farklÄ± filte) resmin kenarlarÄ±nÄ± algÄ±lamasÄ± iÃ§in\n",
        "    layers.Conv2D(32,(3,3), activation ='relu', input_shape=(32,32,3)),\n",
        "\n",
        "    #Pooling: resmi kÃ¼Ã§Ã¼ltÃ¼r ve en Ã¶nemli Ã¶zelliklerini elde tutar.\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    # 2.EvriÅŸim katmanÄ±, daha karmaÅŸÄ±k ÅŸekiller iÃ§in\n",
        "    layers.Conv2D(64,(3,3), activation = 'relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    # 3. EvriÅŸim katmanÄ±\n",
        "    layers.Conv2D(64, (3,3), activation = 'relu'),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10)\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "muSBm8k1sC9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "id": "JCp0cbeN1Lnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"cnn eÄŸitimi baÅŸlÄ±yor\")"
      ],
      "metadata": {
        "id": "H75YEg5R2ZNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = cnn_model.fit(train_images, train_labels, epochs=10, validation_data =(test_images, test_labels))\n",
        "print(\"eÄŸitim bitti\")"
      ],
      "metadata": {
        "id": "nATwaOjh3uI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import  matplotlib.pyplot as plt\n",
        "\n",
        "sample_image = np.random.rand(32, 32, 3)\n",
        "\n",
        "# 2. Modeli test etmek iÃ§in boyutu ayarlÄ±yoruz (1 resim, 32x32, 3 kanal)\n",
        "img_array = np.expand_dims(sample_image, axis=0)\n",
        "\n",
        "predictions =cnn_model.predict(img_array)\n",
        "score =tf.nn.softmax(predictions[0])\n",
        "\n",
        "class_names = ['ucak', 'araba', 'kus', 'kedi', 'geyik', 'kopek', 'kurbaÄŸa', 'at', 'gemi', 'kamyon']\n",
        "print(f\"Bu resim %{100 * np.max(score):.2f} ihtimalle bir {class_names[np.argmax(score)]}.\")\n",
        "\n",
        "plt.imshow(sample_image)\n",
        "plt.title(\"modelin gÃ¶rdÃ¼ÄŸÃ¼ piksel yÄ±ÄŸÄ±nÄ±\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o_V8OumA4Os1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#ilanlar\n",
        "ilanlar = [\n",
        "    \"Harika manzaralÄ± satÄ±lÄ±k lÃ¼ks villa\",\n",
        "    \"Acil satÄ±lÄ±k ucuz daire\",\n",
        "    \"Åžehir merkezinde ferah kiralÄ±k ev\"\n",
        "]\n",
        "\n",
        "tokenizer = Tokenizer(num_words =100)\n",
        "tokenizer.fit_on_texts(ilanlar)\n",
        "sekanslar = tokenizer.texts_to_sequences(ilanlar)\n",
        "\n",
        "veri = pad_sequences(sekanslar, padding = 'post')\n",
        "print(\"kelimelerin sayÄ± karÅŸÄ±lÄ±klarÄ±\", tokenizer.word_index)\n",
        "\n",
        "print(\"cÃ¼mlelerin sayÄ± dizisi hali\" ,veri)"
      ],
      "metadata": {
        "id": "Nxzg1VxNH8r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ä°lk RNN yapÄ±sÄ±\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM,Dense\n",
        "\n",
        "nlp_model= Sequential([\n",
        "    Embedding(input_dim =100, output_dim =16),\n",
        "    LSTM(32),\n",
        "    Dense(1, activation='sigmoid')\n",
        "\n",
        "])\n",
        "\n",
        "nlp_model.compile( optimizer ='adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "nlp_model.summary()\n"
      ],
      "metadata": {
        "id": "9HDHvBNbL4gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 1. VERÄ° HAZIRLAMA\n",
        "cumleler = [\n",
        "    \"harika lÃ¼ks villa\",\n",
        "    \"muhteÅŸem manzaralÄ± daire\",\n",
        "    \"ferah geniÅŸ ev\",\n",
        "    \"bakÄ±msÄ±z eski bina\",\n",
        "    \"rutubetli bodrum kat\",\n",
        "    \"sorunlu acil satÄ±lÄ±k\"\n",
        "]\n",
        "etiketler = np.array([1, 1, 1, 0, 0, 0])\n",
        "\n",
        "# 2. TOKENIZER (Kelimeleri SayÄ±ya Ã‡evirme)\n",
        "tokenizer = Tokenizer(num_words=100)\n",
        "tokenizer.fit_on_texts(cumleler) # Metinleri Ã¶ÄŸren\n",
        "sekanslar = tokenizer.texts_to_sequences(cumleler) # SayÄ±ya Ã§evir\n",
        "veri_hazir = pad_sequences(sekanslar, padding='post') # BoyutlarÄ± eÅŸitle\n",
        "\n",
        "# 3. MODEL MÄ°MARÄ°SÄ°\n",
        "nlp_model = Sequential([\n",
        "    Embedding(input_dim=100, output_dim=16),\n",
        "    LSTM(32),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "nlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 4. EÄžÄ°TÄ°M\n",
        "print(\"EÄŸitim baÅŸlÄ±yor...\")\n",
        "nlp_model.fit(veri_hazir, etiketler, epochs=50, verbose=1)\n",
        "print(\"EÄŸitim tamamlandÄ±!\")"
      ],
      "metadata": {
        "id": "fFMlNUe_Nezr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ilani =[\"bu bina Ã§ok eski ve bakÄ±msÄ±z gÃ¶rÃ¼nÃ¼yor\"]\n",
        "test_sekans=tokenizer.texts_to_sequences(test_ilani)\n",
        "test_hazir = pad_sequences(test_sekans, maxlen=veri_hazir.shape[0], padding='post')\n",
        "\n",
        "sonuc =nlp_model.predict(test_hazir)\n",
        "if sonuc[0][0] > 0.5:\n",
        "    print(\"Yorum: Model bu evi beÄŸendi! ðŸ˜Š\")\n",
        "else:\n",
        "    print(\"Yorum: Model bu evde sorunlar gÃ¶rÃ¼yor. ðŸ˜ž\")"
      ],
      "metadata": {
        "id": "RVyo_x23P0Bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ilani =[\"bu bina Ã§ok harika , muhteÅŸem  gÃ¶rÃ¼nÃ¼yor\"]\n",
        "test_sekans=tokenizer.texts_to_sequences(test_ilani)\n",
        "test_hazir = pad_sequences(test_sekans, maxlen=veri_hazir.shape[0], padding='post')\n",
        "\n",
        "sonuc =nlp_model.predict(test_hazir)\n",
        "if sonuc[0][0] > 0.5:\n",
        "    print(\"Yorum: Model bu evi beÄŸendi! ðŸ˜Š\")\n",
        "else:\n",
        "    print(\"Yorum: Model bu evde sorunlar gÃ¶rÃ¼yor. ðŸ˜ž\")"
      ],
      "metadata": {
        "id": "bs3N_Nm2Wirp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "from transformers import pipeline\n",
        "\n",
        "nlp_dev = pipeline(\"sentiment-analysis\")\n",
        "test_cumlesi = \"bu bina Ã§ok harika , muhteÅŸem ama  eski gÃ¶rÃ¼nÃ¼yor\"\n",
        "sonuc_dev = nlp_dev(test_cumlesi)\n",
        "print(f\"\\n--- TRANSFORMER (BERT) ANALÄ°Z SONUCU ---\")\n",
        "print(f\"CÃ¼mle: {test_cumlesi}\")\n",
        "print(f\"SonuÃ§: {sonuc_dev}\")"
      ],
      "metadata": {
        "id": "XSSyb7mhWtQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "nlp_dev = pipeline(\"sentiment-analysis\")\n",
        "test_cumlesi = \"bu bina Ã§ok harika , muhteÅŸem, eski ama  EskiliÄŸi muazzam bir hava katmÄ±ÅŸ\"\n",
        "sonuc_dev = nlp_dev(test_cumlesi)\n",
        "print(f\"\\n--- TRANSFORMER (BERT) ANALÄ°Z SONUCU ---\")\n",
        "print(f\"CÃ¼mle: {test_cumlesi}\")\n",
        "print(f\"SonuÃ§: {sonuc_dev}\")"
      ],
      "metadata": {
        "id": "SxGieJ_dX6m7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q keras-nlp\n",
        "\n",
        "import keras_nlp\n",
        "import tensorflow as tf\n",
        "\n",
        "classifier = keras_nlp.models.BertClassifier.from_preset(\n",
        "    \"bert_tiny_en_uncased\",\n",
        "    num_classes=2\n",
        ")\n",
        "\n",
        "test_cumlesi = \"harika , muhteÅŸem ama eski\"\n",
        "predictions = classifier.predict([test_cumlesi])\n",
        "\n",
        "print(f\"\\n--- GOOGLE KERAS-NLP SONUCU ---\")\n",
        "print(f\"CÃ¼mle: {test_cumlesi}\")\n",
        "print(f\"Tahmin (Ham Veri): {predictions}\")"
      ],
      "metadata": {
        "id": "86PpE4IeZk8m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}